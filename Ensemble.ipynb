{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import cross_val_score,KFold,train_test_split\n",
    "from sklearn.linear_model import ElasticNet, Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingRegressor,StackingCVRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# environment settings\n",
    "data_path = 'Data/'\n",
    "\n",
    "# Deserialize previously saved data from \"preprocessing\"\n",
    "with open(data_path+'train_pp.obj', 'rb') as train_pp, \\\n",
    "open(data_path+'test_pp.obj','rb') as test_pp:\n",
    "    train_df = pickle.load(train_pp)\n",
    "    test_df = pickle.load(test_pp)\n",
    "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set (1456, 304).\n",
      "Shape of test set (1456,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.loc[:,'Id':'SaleCondition_Partial']\n",
    "y = train_df['SalePrice']\n",
    "print(\"Shape of training set {}.\\nShape of test set {}\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled=scaler.fit(X).transform(X)\n",
    "test_scaled=scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.00065)\n",
    "ENet = ElasticNet(alpha=0.0008,l1_ratio=.55)\n",
    "gBoost = GradientBoostingRegressor(n_estimators=4000, learning_rate=0.03,\n",
    "                                   max_depth=2, max_features='sqrt', \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "xgb= XGBRegressor(colsample_bytree=0.1, gamma=0.03, \n",
    "                             learning_rate=0.02, max_depth=3, \n",
    "                             n_estimators=3000,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best is 0.11484 +/- 0.017 lasso,ENet,xgb,gBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1051 (0.0157)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True, random_state=42).get_n_splits(X)\n",
    "\n",
    "averaged = AveragingModels(models = (gBoost,xgb,ENet,lasso))\n",
    "rmse_cv_avg= np.sqrt(-cross_val_score(averaged, X_scaled, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(rmse_cv_avg.mean(), rmse_cv_avg.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best is  Averaged base models score: 0.1053 (0.0161) <br>\n",
    "ENet,gBoost,lasso,xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prediction on real test set using Stack Regressor\n",
    "averaged.fit(X_scaled,y)\n",
    "pred_results_stack =averaged.predict(test_scaled)\n",
    "pred_results_stack =np.expm1(pred_results_stack)\n",
    "result_df = pd.DataFrame(data={'Id': test_df[\"Id\"].values,\n",
    "                               'SalePrice': pred_results_stack})\n",
    "\n",
    "#Create output csv file\n",
    "result_df.to_csv(data_path+\"outputs/averaged_model\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
